{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "38gxsovoBPhO"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Function to extract video data from YouTube channel URL\n",
        "def scrape_youtube_channel(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    videos = soup.find_all('a', {'class': 'yt-simple-endpoint style-scope ytd-grid-video-renderer'})\n",
        "\n",
        "    video_data = []\n",
        "    for video in videos[:5]:\n",
        "        video_url = 'https://www.youtube.com' + video['href']\n",
        "        thumbnail_url = video.find('img')['src']\n",
        "        title = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).text\n",
        "        views = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).find_next('span').text\n",
        "        post_time = video.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).find_next('span').find_next('span').text\n",
        "\n",
        "        video_data.append({'Video URL': video_url,\n",
        "                           'Thumbnail URL': thumbnail_url,\n",
        "                           'Title': title,\n",
        "                           'Views': views,\n",
        "                           'Post Time': post_time})\n",
        "    return video_data\n",
        "\n",
        "# Function to save video data to CSV file\n",
        "def save_to_csv(data, filename):\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Video URL', 'Thumbnail URL', 'Title', 'Views', 'Post Time']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "# Scrape data from the provided YouTube channel URL\n",
        "youtube_url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
        "video_data = scrape_youtube_channel(youtube_url)\n",
        "\n",
        "# Save scraped data to CSV file\n",
        "save_to_csv(video_data, 'youtube_videos.csv')\n",
        "\n",
        "# Output the first five videos' data\n",
        "for i, video in enumerate(video_data, 1):\n",
        "    print(f\"Video {i}:\")\n",
        "    for key, value in video.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OY0NDLBnBSOz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}